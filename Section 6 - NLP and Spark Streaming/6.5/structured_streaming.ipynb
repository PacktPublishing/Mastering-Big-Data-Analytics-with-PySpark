{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_colwidth = 150\n",
    "\n",
    "# SETTINGS\n",
    "IN_PATH = \"/home/jovyan/data-sets/twitter/\"\n",
    "OUT_PATH = \"\"\n",
    "timestampformat = \"EEE MMM dd HH:mm:ss zzzz yyyy\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StructuredStreamingExample\").getOrCreate()\n",
    "schema = spark.read.json(IN_PATH).limit(10).schema\n",
    "\n",
    "# regular spark reader\n",
    "static_spark_reader = spark.read.schema(schema)\n",
    "\n",
    "# streaming spark reader\n",
    "stream_spark_reader = spark.readStream.schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle between spark streaming and batch mode by changing the spark_reader below\n",
    "# spark_reader = static_spark_reader\n",
    "spark_reader = stream_spark_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark_reader.json(IN_PATH)\n",
    "    .select(\n",
    "        \"id\",\n",
    "        # extract proper timestamp from created_at column\n",
    "        f.to_timestamp(f.col(\"created_at\"), timestampformat).alias(\"timestamp\"),\n",
    "        # extract user information\n",
    "        f.col(\"user.screen_name\").alias(\"user\"),\n",
    "        \"text\",\n",
    "    )\n",
    "    .coalesce(1)\n",
    ")\n",
    "\n",
    "distinct_user_count = df.select(f.approx_count_distinct(\"user\"), f.current_timestamp())\n",
    "\n",
    "if not df.isStreaming:\n",
    "    print(\"Plain old, basic DataFrame - meh!\")\n",
    "    # Some actions only work on non-streaming DataFrames, like show and toPandas\n",
    "    distinct_user_count.show()\n",
    "    display(df.limit(25).toPandas())\n",
    "else:\n",
    "    print(\"We are streaming!\")\n",
    "    # Creating a DataSreamWriter and StreamingQuery\n",
    "    # ===\n",
    "    # Calling .writeStream on a DataFrame returns an instance of DataStreamWriter\n",
    "    stream_writer = (\n",
    "        distinct_user_count.writeStream\n",
    "        # DataStream queries need to be named\n",
    "        .queryName(\"distinct_user_count\")\n",
    "        .trigger(\n",
    "            # processingTime=\"5 seconds\",\n",
    "            # Setting 'once' to True will make spark only process the stream 1 time - great for debugging\n",
    "            once=True,  \n",
    "        )\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"memory\")\n",
    "    )\n",
    "    # Calling .start on a DataStreamWriter return an instance of StreamingQuery\n",
    "    query = stream_writer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isStreaming can be used to determine if DataFrame is of Streaming kind or not\n",
    "df.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isActive shows if the query is actively running or not\n",
    "query.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .start() transforms a DataStreamWriter to a StreamingQuery and starts the query execution\n",
    "if not query.isActive:\n",
    "    query = stream_writer.start()\n",
    "    \n",
    "# Calling .start on an already active StreamingQuery will raise an IllegalArgumentException\n",
    "# -> 'Cannot start query with name {StreamingQuery.name} as a query with that name is already active'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .stop() stops the query\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .lastProgress shows information on the last processed batch\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql can be used to request how the query is performing\n",
    "display(spark.sql(f\"SELECT * from {query.name}\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show live results for 2 minutes, refreshed every 1 second\n",
    "from time import sleep\n",
    "for x in range(0, 120):\n",
    "    # spark.sql can be used to request how the query is performing\n",
    "    display(spark.sql(f\"SELECT * from {query.name}\").toPandas())\n",
    "    sleep(1)\n",
    "    clear_output(wait=True)\n",
    "else:\n",
    "    print(\"Live view ended...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .show() will throw an error on Queries and Streaming DataFrames\n",
    "distinct_user_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
